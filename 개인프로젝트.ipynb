{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ea54f570bea2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#웹캠에서 영상을 읽어온다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m640\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#WIDTH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m480\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#HEIGHT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "#웹캠에서 영상을 읽어온다\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640) #WIDTH\n",
    "cap.set(4, 480) #HEIGHT\n",
    "\n",
    "#얼굴 인식 캐스케이드 파일 읽는다\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontface.xml')\n",
    "\n",
    "while(True):\n",
    "    # frame 별로 capture 한다\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    #인식된 얼굴 갯수를 출력\n",
    "    print(len(faces))\n",
    "\n",
    "    # 인식된 얼굴에 사각형을 출력한다\n",
    "    for (x,y,w,h) in faces:\n",
    "         cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "    #화면에 출력한다\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일단 되는 거 바로 아래것 근데 이상함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Gender : Male, conf = 0.995\n",
      "Age Output : [[1.6725605e-06 3.6393561e-05 9.6293896e-01 4.0181517e-03 3.2947931e-02\n",
      "  4.9496415e-05 5.8362402e-06 1.4572593e-06]]\n",
      "Age : (8-12), conf = 0.963\n",
      "1\n",
      "Gender : Male, conf = 0.997\n",
      "Age Output : [[8.4271005e-07 6.5539636e-05 9.8994195e-01 2.2956629e-03 7.6797535e-03\n",
      "  1.3612901e-05 2.1381234e-06 4.9333113e-07]]\n",
      "Age : (8-12), conf = 0.990\n",
      "1\n",
      "Gender : Male, conf = 0.997\n",
      "Age Output : [[1.0533052e-05 3.4926846e-04 7.2559434e-01 2.0366764e-02 2.5345132e-01\n",
      "  1.9788998e-04 2.3769715e-05 6.0177258e-06]]\n",
      "Age : (8-12), conf = 0.726\n",
      "1\n",
      "Gender : Male, conf = 0.981\n",
      "Age Output : [[2.1688527e-05 1.8081801e-04 1.8741930e-01 1.6652426e-02 7.9467386e-01\n",
      "  1.0015657e-03 3.4401543e-05 1.5935213e-05]]\n",
      "Age : (25-32), conf = 0.795\n",
      "1\n",
      "Gender : Male, conf = 0.985\n",
      "Age Output : [[2.4877654e-05 6.0366339e-04 3.7068254e-01 1.4871839e-02 6.1344147e-01\n",
      "  3.4061409e-04 2.4371269e-05 1.0711863e-05]]\n",
      "Age : (25-32), conf = 0.613\n",
      "1\n",
      "Gender : Male, conf = 0.971\n",
      "Age Output : [[2.6180358e-06 3.5959724e-04 9.8713094e-01 2.8629948e-03 9.6245594e-03\n",
      "  1.5322181e-05 2.8892091e-06 1.0347577e-06]]\n",
      "Age : (8-12), conf = 0.987\n",
      "1\n",
      "Gender : Male, conf = 0.833\n",
      "Age Output : [[5.9524764e-06 8.5006934e-04 9.9845791e-01 1.5045125e-04 5.3355185e-04\n",
      "  1.7153596e-06 2.0832131e-07 1.4092875e-07]]\n",
      "Age : (8-12), conf = 0.998\n",
      "1\n",
      "Gender : Male, conf = 0.991\n",
      "Age Output : [[1.9694910e-06 1.5911553e-04 9.9345350e-01 6.4269872e-04 5.7295249e-03\n",
      "  1.1319392e-05 1.3075247e-06 5.4888977e-07]]\n",
      "Age : (8-12), conf = 0.993\n",
      "1\n",
      "Gender : Male, conf = 0.964\n",
      "Age Output : [[1.7865033e-06 2.6089684e-04 9.9560863e-01 1.2262263e-04 4.0000877e-03\n",
      "  4.7700782e-06 8.9114701e-07 3.1296710e-07]]\n",
      "Age : (8-12), conf = 0.996\n",
      "1\n",
      "Gender : Male, conf = 0.958\n",
      "Age Output : [[5.9945512e-07 2.4304712e-04 9.9727136e-01 2.1144208e-04 2.2706036e-03\n",
      "  2.3359505e-06 4.9399256e-07 1.2305927e-07]]\n",
      "Age : (8-12), conf = 0.997\n",
      "1\n",
      "Gender : Male, conf = 0.986\n",
      "Age Output : [[6.7860498e-07 9.9876772e-05 9.7950238e-01 3.5302055e-03 1.6837068e-02\n",
      "  2.5041141e-05 4.3442246e-06 5.5684615e-07]]\n",
      "Age : (8-12), conf = 0.980\n",
      "1\n",
      "Gender : Male, conf = 0.996\n",
      "Age Output : [[3.92252587e-05 9.27491928e-04 7.77798057e-01 9.99310315e-02\n",
      "  1.20871305e-01 3.72525537e-04 4.72704050e-05 1.30565641e-05]]\n",
      "Age : (8-12), conf = 0.778\n",
      "1\n",
      "Gender : Male, conf = 0.934\n",
      "Age Output : [[4.0794080e-06 4.2840821e-04 9.2039621e-01 6.0667209e-03 7.3028080e-02\n",
      "  5.7951631e-05 1.6191201e-05 2.3346026e-06]]\n",
      "Age : (8-12), conf = 0.920\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv2\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def getFaceBox(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    bboxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn, bboxes\n",
    "\n",
    "\n",
    "faceProto = \"opencv_face_detector.pbtxt\"\n",
    "faceModel = \"opencv_face_detector_uint8.pb\"\n",
    "\n",
    "ageProto = \"age_deploy.prototxt\"\n",
    "ageModel = \"age_net.caffemodel\"\n",
    "\n",
    "genderProto = \"gender_deploy.prototxt\"\n",
    "genderModel = \"gender_net.caffemodel\"\n",
    "\n",
    "\n",
    "ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "genderList = ['Male', 'Female']\n",
    "\n",
    "# Load network\n",
    "ageNet = cv2.dnn.readNet(ageModel, ageProto)\n",
    "genderNet = cv2.dnn.readNet(genderModel, genderProto)\n",
    "faceNet = cv2.dnn.readNet(faceModel, faceProto)\n",
    "\n",
    "\n",
    "#웹캠에서 영상을 읽어온다\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640) #WIDTH\n",
    "cap.set(4, 480) #HEIGHT\n",
    "\n",
    "#얼굴 인식 캐스케이드 파일 읽는다\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontface.xml')\n",
    "\n",
    "while(True):\n",
    "    # frame 별로 capture 한다\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    #인식된 얼굴 갯수를 출력\n",
    "    print(len(faces))\n",
    "\n",
    "    # 인식된 얼굴에 사각형을 출력한다\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "            \n",
    "    frameFace, bboxes = getFaceBox(faceNet, frame)   # 얼굴찾는 함수\n",
    "    padding = 10\n",
    "    for bbox in bboxes:\n",
    "        face = frame[max(0,bbox[1]-padding):min(bbox[3]+padding,frame.shape[0]-1),max(0,bbox[0]-padding):min(bbox[2]+padding, frame.shape[1]-1)]\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227),(78.4263377603, 87.7689143744, 114.895847746), swapRB=False)\n",
    "        genderNet.setInput(blob)\n",
    "        genderPreds = genderNet.forward()\n",
    "        gender = genderList[genderPreds[0].argmax()]\n",
    "        print(\"Gender : {}, conf = {:.3f}\".format(gender, genderPreds[0].max()))\n",
    "\n",
    "        ageNet.setInput(blob)\n",
    "        agePreds = ageNet.forward()\n",
    "        age = ageList[agePreds[0].argmax()]\n",
    "        print(\"Age Output : {}\".format(agePreds))\n",
    "        print(\"Age : {}, conf = {:.3f}\".format(age, agePreds[0].max()))\n",
    "\n",
    "        label = \"{},{}\".format(gender, age)\n",
    "        cv2.putText(frameFace, label, (bbox[0], bbox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA)        \n",
    "        \n",
    "    #화면에 출력한다\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.imwrite(\"age-gender-out.jpg\", frameFace)\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신호가 들어올때 검출하는 저장키 같은것 만들자\n",
    "아니면 시간이 어느정도 지낫을때의 조건을 줘서 저장하게\n",
    "\n",
    "\n",
    "frame에 또 frame이 들어가서 2개가 생김"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 저장키값까지 성공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Gender : Male, conf = 0.999\n",
      "Age Output : [[2.3317210e-02 3.4624875e-01 5.6116456e-01 8.9519816e-03 5.9507996e-02\n",
      "  7.3434529e-04 5.7617402e-05 1.7567323e-05]]\n",
      "Age : (8-12), conf = 0.561\n",
      "1\n",
      "Gender : Male, conf = 0.999\n",
      "Age Output : [[6.4319768e-04 2.2532355e-02 8.5403025e-01 4.1792210e-02 7.9911791e-02\n",
      "  1.0334610e-03 4.7317651e-05 9.3998751e-06]]\n",
      "Age : (8-12), conf = 0.854\n",
      "1\n",
      "Gender : Male, conf = 0.999\n",
      "Age Output : [[3.8958449e-02 4.1797557e-01 4.9334624e-01 4.2392332e-03 4.5040876e-02\n",
      "  3.7364539e-04 5.2107043e-05 1.3803438e-05]]\n",
      "Age : (8-12), conf = 0.493\n",
      "1\n",
      "Gender : Male, conf = 0.999\n",
      "Age Output : [[5.6406448e-04 1.3054496e-02 9.2526203e-01 9.1658486e-03 5.1548667e-02\n",
      "  3.9017556e-04 1.1784876e-05 2.9391276e-06]]\n",
      "Age : (8-12), conf = 0.925\n",
      "1\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[2.1165501e-02 2.4246037e-01 6.4995915e-01 6.3288193e-03 7.9643719e-02\n",
      "  3.8709474e-04 4.5421428e-05 9.9406370e-06]]\n",
      "Age : (8-12), conf = 0.650\n",
      "1\n",
      "Gender : Male, conf = 0.999\n",
      "Age Output : [[5.7825208e-02 5.1482534e-01 3.9372665e-01 2.5006614e-03 3.0716538e-02\n",
      "  3.1174452e-04 7.7475408e-05 1.6387401e-05]]\n",
      "Age : (4-6), conf = 0.515\n",
      "1\n",
      "Gender : Male, conf = 0.999\n",
      "Age Output : [[1.2723366e-03 1.3848943e-02 9.6388310e-01 5.2161687e-03 1.5708562e-02\n",
      "  5.3614509e-05 1.4695560e-05 2.5125539e-06]]\n",
      "Age : (8-12), conf = 0.964\n",
      "1\n",
      "Gender : Male, conf = 0.998\n",
      "Age Output : [[6.3619023e-04 2.2769257e-02 9.7252196e-01 4.2118449e-04 3.6179726e-03\n",
      "  2.6865340e-05 5.4954908e-06 1.0745952e-06]]\n",
      "Age : (8-12), conf = 0.973\n",
      "1\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[1.82675291e-02 1.40636176e-01 8.28126431e-01 4.81364259e-04\n",
      "  1.23498077e-02 1.14210605e-04 1.82720250e-05 6.18665081e-06]]\n",
      "Age : (8-12), conf = 0.828\n",
      "1\n",
      "Gender : Male, conf = 0.999\n",
      "Age Output : [[7.2201360e-03 5.6871481e-02 9.2885250e-01 1.2796164e-03 5.7015433e-03\n",
      "  5.4585878e-05 1.5322579e-05 4.9053087e-06]]\n",
      "Age : (8-12), conf = 0.929\n",
      "1\n",
      "Gender : Male, conf = 0.999\n",
      "Age Output : [[2.9692104e-02 9.7774275e-02 8.5990775e-01 9.0589694e-04 1.1464691e-02\n",
      "  1.8176087e-04 5.7415695e-05 1.6223858e-05]]\n",
      "Age : (8-12), conf = 0.860\n",
      "1\n",
      "Gender : Male, conf = 0.999\n",
      "Age Output : [[4.3974183e-03 8.0885757e-03 9.4769537e-01 2.2841209e-04 3.8546901e-02\n",
      "  8.3434611e-04 1.7165802e-04 3.7344620e-05]]\n",
      "Age : (8-12), conf = 0.948\n",
      "1\n",
      "Gender : Male, conf = 0.996\n",
      "Age Output : [[4.9116241e-04 9.6940837e-04 8.0948305e-01 1.1889902e-03 1.8736121e-01\n",
      "  2.9761091e-04 1.8332021e-04 2.5291423e-05]]\n",
      "Age : (8-12), conf = 0.809\n",
      "1\n",
      "Gender : Male, conf = 0.989\n",
      "Age Output : [[7.28209443e-06 2.94104597e-04 9.56155539e-01 9.96706169e-03\n",
      "  3.35512049e-02 1.23657665e-05 1.13474225e-05 1.05846334e-06]]\n",
      "Age : (8-12), conf = 0.956\n",
      "1\n",
      "Gender : Male, conf = 0.968\n",
      "Age Output : [[1.4551379e-05 2.3780928e-03 9.4761765e-01 1.3829078e-02 3.6143422e-02\n",
      "  1.0660464e-05 5.9459148e-06 7.2475245e-07]]\n",
      "Age : (8-12), conf = 0.948\n",
      "1\n",
      "Gender : Male, conf = 0.980\n",
      "Age Output : [[1.03295870e-05 1.76455040e-04 5.77852845e-01 9.33877565e-03\n",
      "  4.12560433e-01 4.68869875e-05 1.28098045e-05 1.36822553e-06]]\n",
      "Age : (8-12), conf = 0.578\n",
      "1\n",
      "Gender : Male, conf = 0.994\n",
      "Age Output : [[1.1875965e-05 5.2976701e-03 9.5700085e-01 9.8950462e-03 2.7730953e-02\n",
      "  3.0903364e-05 3.0213812e-05 2.4922383e-06]]\n",
      "Age : (8-12), conf = 0.957\n",
      "1\n",
      "Gender : Male, conf = 0.991\n",
      "Age Output : [[5.5601413e-06 6.7864799e-05 4.1410115e-02 2.8852947e-02 9.2933655e-01\n",
      "  2.8010563e-04 3.8974151e-05 7.9140555e-06]]\n",
      "Age : (25-32), conf = 0.929\n",
      "1\n",
      "Gender : Male, conf = 0.997\n",
      "Age Output : [[3.3819870e-06 9.6578086e-05 2.4781063e-01 9.2309527e-02 6.5936339e-01\n",
      "  3.7410838e-04 3.3766413e-05 8.5633446e-06]]\n",
      "Age : (25-32), conf = 0.659\n",
      "1\n",
      "Gender : Male, conf = 0.987\n",
      "Age Output : [[2.3657090e-06 1.9013391e-04 9.5875889e-01 2.4460068e-02 1.6560748e-02\n",
      "  2.3998404e-05 3.0850770e-06 8.0939787e-07]]\n",
      "Age : (8-12), conf = 0.959\n",
      "1\n",
      "Gender : Male, conf = 0.999\n",
      "Age Output : [[5.2271880e-05 8.7951979e-04 5.1227696e-02 1.3405877e-02 9.3267846e-01\n",
      "  1.6878834e-03 5.3332496e-05 1.4871678e-05]]\n",
      "Age : (25-32), conf = 0.933\n",
      "0\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[7.7951408e-05 1.1154357e-02 8.5110110e-01 3.2911807e-02 1.0416113e-01\n",
      "  5.2058976e-04 6.4854517e-05 8.2404140e-06]]\n",
      "Age : (8-12), conf = 0.851\n",
      "0\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[5.32965059e-05 1.46077797e-02 5.53326786e-01 1.09844334e-01\n",
      "  3.19910973e-01 2.10924190e-03 1.26198720e-04 2.13532021e-05]]\n",
      "Age : (8-12), conf = 0.553\n",
      "0\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[2.2100596e-02 4.1100991e-01 2.1854942e-01 6.4604126e-02 2.7187163e-01\n",
      "  1.1140610e-02 5.1860337e-04 2.0502161e-04]]\n",
      "Age : (4-6), conf = 0.411\n",
      "0\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[1.8131632e-02 8.2049835e-01 1.0007214e-01 9.9760368e-03 5.0016735e-02\n",
      "  1.1580314e-03 1.0912358e-04 3.7980710e-05]]\n",
      "Age : (4-6), conf = 0.820\n",
      "0\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[9.9766618e-03 7.6426899e-01 1.4430942e-01 9.0289209e-03 7.1458168e-02\n",
      "  8.5862260e-04 8.0467697e-05 1.8822791e-05]]\n",
      "Age : (4-6), conf = 0.764\n",
      "0\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[2.2369169e-02 4.9590048e-01 2.7106035e-01 2.6849264e-02 1.8075393e-01\n",
      "  2.7579833e-03 2.4827771e-04 6.0425915e-05]]\n",
      "Age : (4-6), conf = 0.496\n",
      "0\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[9.9584810e-05 8.9025432e-03 7.4505258e-01 6.2869698e-02 1.8135580e-01\n",
      "  1.6706585e-03 4.0698309e-05 8.4443918e-06]]\n",
      "Age : (8-12), conf = 0.745\n",
      "1\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[1.4879417e-06 5.7146285e-06 6.0955111e-02 1.9795330e-02 9.1824853e-01\n",
      "  9.7731559e-04 1.2345846e-05 4.1611975e-06]]\n",
      "Age : (25-32), conf = 0.918\n",
      "1\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[4.0862601e-06 4.9622380e-04 8.1497699e-01 1.0138815e-01 8.2560971e-02\n",
      "  5.6441134e-04 7.2966145e-06 1.8122897e-06]]\n",
      "Age : (8-12), conf = 0.815\n",
      "1\n",
      "Gender : Male, conf = 0.998\n",
      "Age Output : [[3.5703245e-06 6.5271997e-05 9.7764230e-01 2.1090736e-03 2.0022543e-02\n",
      "  1.4367873e-04 5.7747739e-06 7.6911438e-06]]\n",
      "Age : (8-12), conf = 0.978\n",
      "1\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[5.2729474e-06 9.1377285e-04 9.9286592e-01 2.0673405e-03 4.0535145e-03\n",
      "  9.0521127e-05 2.4370574e-06 1.0677412e-06]]\n",
      "Age : (8-12), conf = 0.993\n",
      "1\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[2.8983691e-06 3.5083230e-04 9.9202335e-01 2.6441773e-03 4.7435570e-03\n",
      "  2.3006705e-04 3.6234032e-06 1.4946996e-06]]\n",
      "Age : (8-12), conf = 0.992\n",
      "1\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[9.9684416e-07 9.6630545e-05 9.9284160e-01 3.2458305e-03 3.5701990e-03\n",
      "  2.4068102e-04 2.8973895e-06 1.1374530e-06]]\n",
      "Age : (8-12), conf = 0.993\n",
      "1\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[7.2224025e-06 3.3876964e-05 8.6329019e-01 2.1195619e-03 1.3419175e-01\n",
      "  3.2798733e-04 2.4623178e-05 4.8574361e-06]]\n",
      "Age : (8-12), conf = 0.863\n",
      "1\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[1.8496860e-02 2.2428562e-01 7.4091023e-01 5.0907587e-03 1.1010100e-02\n",
      "  1.6682979e-04 2.7183616e-05 1.2388819e-05]]\n",
      "Age : (8-12), conf = 0.741\n",
      "1\n",
      "Gender : Male, conf = 1.000\n",
      "Age Output : [[1.19872561e-06 3.33168464e-05 9.76135612e-01 1.05897095e-02\n",
      "  1.26739796e-02 5.56528044e-04 7.26962253e-06 2.31057766e-06]]\n",
      "Age : (8-12), conf = 0.976\n",
      "1\n",
      "Gender : Male, conf = 0.999\n",
      "Age Output : [[1.9194344e-05 2.1823426e-03 9.8510426e-01 2.2533706e-03 1.0301401e-02\n",
      "  1.3353815e-04 4.6285813e-06 1.3727400e-06]]\n",
      "Age : (8-12), conf = 0.985\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv2\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def getFaceBox(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    bboxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn, bboxes\n",
    "\n",
    "\n",
    "faceProto = \"opencv_face_detector.pbtxt\"\n",
    "faceModel = \"opencv_face_detector_uint8.pb\"\n",
    "\n",
    "ageProto = \"age_deploy.prototxt\"\n",
    "ageModel = \"age_net.caffemodel\"\n",
    "\n",
    "genderProto = \"gender_deploy.prototxt\"\n",
    "genderModel = \"gender_net.caffemodel\"\n",
    "\n",
    "\n",
    "ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "genderList = ['Male', 'Female']\n",
    "\n",
    "# Load network\n",
    "ageNet = cv2.dnn.readNet(ageModel, ageProto)\n",
    "genderNet = cv2.dnn.readNet(genderModel, genderProto)\n",
    "faceNet = cv2.dnn.readNet(faceModel, faceProto)\n",
    "\n",
    "\n",
    "#웹캠에서 영상을 읽어온다\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640) #WIDTH\n",
    "cap.set(4, 480) #HEIGHT\n",
    "\n",
    "#얼굴 인식 캐스케이드 파일 읽는다\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontface.xml')\n",
    "\n",
    "while(True):\n",
    "    # frame 별로 capture 한다\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    #인식된 얼굴 갯수를 출력\n",
    "    print(len(faces))\n",
    "\n",
    "    # 인식된 얼굴에 사각형을 출력한다\n",
    "    for (x1,y1,x2,y2) in faces:\n",
    "        cv2.rectangle(frame,(x1,y1),(x1+x2,y1+y2),(255,0,0),2)\n",
    "\n",
    "            \n",
    "    frameFace, bboxes = getFaceBox(faceNet, frame)   # 얼굴찾는 함수\n",
    "    padding = 10\n",
    "    for bbox in bboxes:\n",
    "        face = frame[max(0,bbox[1]-padding):min(bbox[3]+padding,frame.shape[0]-1),max(0,bbox[0]-padding):min(bbox[2]+padding, frame.shape[1]-1)]\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227),(78.4263377603, 87.7689143744, 114.895847746), swapRB=False)\n",
    "        genderNet.setInput(blob)\n",
    "        genderPreds = genderNet.forward()\n",
    "        gender = genderList[genderPreds[0].argmax()]\n",
    "        print(\"Gender : {}, conf = {:.3f}\".format(gender, genderPreds[0].max()))\n",
    "\n",
    "        ageNet.setInput(blob)\n",
    "        agePreds = ageNet.forward()\n",
    "        age = ageList[agePreds[0].argmax()]\n",
    "        print(\"Age Output : {}\".format(agePreds))\n",
    "        print(\"Age : {}, conf = {:.3f}\".format(age, agePreds[0].max()))\n",
    "\n",
    "        label = \"{},{}\".format(gender, age)\n",
    "        cv2.putText(frameFace, label, (bbox[0], bbox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA)        \n",
    "        \n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    k = cv2.waitKey(5)\n",
    "    if k == ord('q'): # esc key\n",
    "        break\n",
    "    elif k == ord('s'): # 's' key\n",
    "        cv2.imwrite('testface.png',frameFace)\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv2\n",
    "from flask import Flask , Response , render_template\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "app = Flask(__name__)\n",
    "\n",
    "def stream():\n",
    "    while 1 :\n",
    "        __,frame = cam.read()\n",
    "        imgencode = cv2.imencode('.jpg',frame)[1]\n",
    "        stringData = imgencode.tostring()\n",
    "        yield (b'--frame\\r\\n'b'Content-Type: text/plain\\r\\n\\r\\n'+stringData+b'\\r\\n')\n",
    "\n",
    "@app.route('/video')\n",
    "def video():\n",
    "    return Response(stream(),mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/')\n",
    "def main():\n",
    "    return render_template('index.html')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "<html>\n",
    "    <img src=\"{{ url_for('video')}}\">\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# github에서 django 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1121: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"age_deploy.prototxt\" in function 'cv::dnn::ReadProtoFromTextFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f92750533457>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# Load network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mageNet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mageModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mageProto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[0mgenderNet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenderModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenderProto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mfaceNet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaceModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfaceProto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1121: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"age_deploy.prototxt\" in function 'cv::dnn::ReadProtoFromTextFile'\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv2\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def getFaceBox(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    bboxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn, bboxes\n",
    "\n",
    "\n",
    "faceProto = \"opencv_face_detector.pbtxt\"\n",
    "faceModel = \"opencv_face_detector_uint8.pb\"\n",
    "\n",
    "ageProto = \"age_deploy.prototxt\"\n",
    "ageModel = \"age_net.caffemodel\"\n",
    "\n",
    "genderProto = \"gender_deploy.prototxt\"\n",
    "genderModel = \"gender_net.caffemodel\"\n",
    "\n",
    "\n",
    "ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "genderList = ['Male', 'Female']\n",
    "\n",
    "# Load network\n",
    "ageNet = cv2.dnn.readNet(ageModel, ageProto)\n",
    "genderNet = cv2.dnn.readNet(genderModel, genderProto)\n",
    "faceNet = cv2.dnn.readNet(faceModel, faceProto)\n",
    "\n",
    "\n",
    "#웹캠에서 영상을 읽어온다\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640) #WIDTH\n",
    "cap.set(4, 480) #HEIGHT\n",
    "\n",
    "#얼굴 인식 캐스케이드 파일 읽는다\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontface.xml')\n",
    "\n",
    "while(True):\n",
    "    # frame 별로 capture 한다\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    #인식된 얼굴 갯수를 출력\n",
    "    print(len(faces))\n",
    "\n",
    "    # 인식된 얼굴에 사각형을 출력한다\n",
    "    for (x1,y1,x2,y2) in faces:\n",
    "        cv2.rectangle(frame,(x1,y1),(x1+x2,y1+y2),(255,0,0),2)\n",
    "\n",
    "            \n",
    "    frameFace, bboxes = getFaceBox(faceNet, frame)   # 얼굴찾는 함수\n",
    "    padding = 10\n",
    "    for bbox in bboxes:\n",
    "        face = frame[max(0,bbox[1]-padding):min(bbox[3]+padding,frame.shape[0]-1),max(0,bbox[0]-padding):min(bbox[2]+padding, frame.shape[1]-1)]\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227),(78.4263377603, 87.7689143744, 114.895847746), swapRB=False)\n",
    "        genderNet.setInput(blob)\n",
    "        genderPreds = genderNet.forward()\n",
    "        gender = genderList[genderPreds[0].argmax()]\n",
    "        print(\"Gender : {}, conf = {:.3f}\".format(gender, genderPreds[0].max()))\n",
    "\n",
    "        ageNet.setInput(blob)\n",
    "        agePreds = ageNet.forward()\n",
    "        age = ageList[agePreds[0].argmax()]\n",
    "        print(\"Age Output : {}\".format(agePreds))\n",
    "        print(\"Age : {}, conf = {:.3f}\".format(age, agePreds[0].max()))\n",
    "\n",
    "        label = \"{},{}\".format(gender, age)\n",
    "        cv2.putText(frameFace, label, (bbox[0], bbox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA)        \n",
    "        \n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    k = cv2.waitKey(5)\n",
    "    if k == ord('q'): # esc key\n",
    "        break\n",
    "    elif k == ord('s'): # 's' key\n",
    "        cv2.imwrite('testface.png',frameFace)\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웹캠에서 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Documentation: https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "\n",
    "#-----------------------\n",
    "#you can find male and female icons here: https://github.com/serengil/tensorflow-101/tree/master/dataset\n",
    "\n",
    "enableGenderIcons = True\n",
    "\n",
    "male_icon = cv2.imread(\"male.jpg\")\n",
    "male_icon = cv2.resize(male_icon, (40, 40))\n",
    "\n",
    "female_icon = cv2.imread(\"female.jpg\")\n",
    "female_icon = cv2.resize(female_icon, (40, 40))\n",
    "#-----------------------\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def loadVggFaceModel():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "\tmodel.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "\tmodel.add(ZeroPadding2D((1,1)))\n",
    "\tmodel.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "\tmodel.add(ZeroPadding2D((1,1)))\n",
    "\tmodel.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "\tmodel.add(ZeroPadding2D((1,1)))\n",
    "\tmodel.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "\tmodel.add(ZeroPadding2D((1,1)))\n",
    "\tmodel.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "\tmodel.add(ZeroPadding2D((1,1)))\n",
    "\tmodel.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "\tmodel.add(ZeroPadding2D((1,1)))\n",
    "\tmodel.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "\tmodel.add(ZeroPadding2D((1,1)))\n",
    "\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "\tmodel.add(ZeroPadding2D((1,1)))\n",
    "\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "\tmodel.add(ZeroPadding2D((1,1)))\n",
    "\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "\tmodel.add(ZeroPadding2D((1,1)))\n",
    "\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "\tmodel.add(ZeroPadding2D((1,1)))\n",
    "\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "\tmodel.add(ZeroPadding2D((1,1)))\n",
    "\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "\tmodel.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Convolution2D(2622, (1, 1)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\t\n",
    "\treturn model\n",
    "\n",
    "def ageModel():\n",
    "\tmodel = loadVggFaceModel()\n",
    "\t\n",
    "\tbase_model_output = Sequential()\n",
    "\tbase_model_output = Convolution2D(101, (1, 1), name='predictions')(model.layers[-4].output)\n",
    "\tbase_model_output = Flatten()(base_model_output)\n",
    "\tbase_model_output = Activation('softmax')(base_model_output)\n",
    "\t\n",
    "\tage_model = Model(inputs=model.input, outputs=base_model_output)\n",
    "\t\n",
    "\t#you can find the pre-trained weights for age prediction here: https://drive.google.com/file/d/1YCox_4kJ-BYeXq27uUbasu--yz28zUMV/view?usp=sharing\n",
    "\tage_model.load_weights(\"age_model_weights.h5\")\n",
    "\t\n",
    "\treturn age_model\n",
    "\n",
    "def genderModel():\n",
    "\tmodel = loadVggFaceModel()\n",
    "\t\n",
    "\tbase_model_output = Sequential()\n",
    "\tbase_model_output = Convolution2D(2, (1, 1), name='predictions')(model.layers[-4].output)\n",
    "\tbase_model_output = Flatten()(base_model_output)\n",
    "\tbase_model_output = Activation('softmax')(base_model_output)\n",
    "\n",
    "\tgender_model = Model(inputs=model.input, outputs=base_model_output)\n",
    "\t\n",
    "\t#you can find the pre-trained weights for gender prediction here: https://drive.google.com/file/d/1wUXRVlbsni2FN9-jkS_f4UTUrm1bRLyk/view?usp=sharing\n",
    "\tgender_model.load_weights(\"gender_model_weights.h5\")\n",
    "\t\n",
    "\treturn gender_model\n",
    "\t\n",
    "age_model = ageModel()\n",
    "gender_model = genderModel()\n",
    "\n",
    "#age model has 101 outputs and its outputs will be multiplied by its index label. sum will be apparent age\n",
    "output_indexes = np.array([i for i in range(0, 101)])\n",
    "\n",
    "#------------------------\n",
    "\n",
    "cap = cv2.VideoCapture(0) #capture webcam\n",
    "\n",
    "while(True):\n",
    "\tret, img = cap.read()\n",
    "\t#img = cv2.resize(img, (640, 360))\n",
    "\t\n",
    "\tfaces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\t\n",
    "\tfor (x,y,w,h) in faces:\n",
    "\t\tif w > 130: #ignore small faces\n",
    "\t\t\t\n",
    "\t\t\t#mention detected face\n",
    "\t\t\t\"\"\"overlay = img.copy(); output = img.copy(); opacity = 0.6\n",
    "\t\t\tcv2.rectangle(img,(x,y),(x+w,y+h),(128,128,128),cv2.FILLED) #draw rectangle to main image\n",
    "\t\t\tcv2.addWeighted(overlay, opacity, img, 1 - opacity, 0, img)\"\"\"\n",
    "\t\t\tcv2.rectangle(img,(x,y),(x+w,y+h),(128,128,128),1) #draw rectangle to main image\n",
    "\t\t\t\n",
    "\t\t\t#extract detected face\n",
    "\t\t\tdetected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "\t\t\t\n",
    "\t\t\ttry:\n",
    "\t\t\t\t#age gender data set has 40% margin around the face. expand detected face.\n",
    "\t\t\t\tmargin = 30\n",
    "\t\t\t\tmargin_x = int((w * margin)/100); margin_y = int((h * margin)/100)\n",
    "\t\t\t\tdetected_face = img[int(y-margin_y):int(y+h+margin_y), int(x-margin_x):int(x+w+margin_x)]\n",
    "\t\t\texcept:\n",
    "\t\t\t\tprint(\"detected face has no margin\")\n",
    "\t\t\t\n",
    "\t\t\ttry:\n",
    "\t\t\t\t#vgg-face expects inputs (224, 224, 3)\n",
    "\t\t\t\tdetected_face = cv2.resize(detected_face, (224, 224))\n",
    "\t\t\t\t\n",
    "\t\t\t\timg_pixels = image.img_to_array(detected_face)\n",
    "\t\t\t\timg_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\t\t\t\timg_pixels /= 255\n",
    "\t\t\t\t\n",
    "\t\t\t\t#find out age and gender\n",
    "\t\t\t\tage_distributions = age_model.predict(img_pixels)\n",
    "\t\t\t\tapparent_age = str(int(np.floor(np.sum(age_distributions * output_indexes, axis = 1))[0]))\n",
    "\t\t\t\t\n",
    "\t\t\t\tgender_distribution = gender_model.predict(img_pixels)[0]\n",
    "\t\t\t\tgender_index = np.argmax(gender_distribution)\n",
    "\t\t\t\t\n",
    "\t\t\t\tif gender_index == 0: gender = \"F\"\n",
    "\t\t\t\telse: gender = \"M\"\n",
    "\t\t\t\n",
    "\t\t\t\t#background for age gender declaration\n",
    "\t\t\t\tinfo_box_color = (46,200,255)\n",
    "\t\t\t\t#triangle_cnt = np.array( [(x+int(w/2), y+10), (x+int(w/2)-25, y-20), (x+int(w/2)+25, y-20)] )\n",
    "\t\t\t\ttriangle_cnt = np.array( [(x+int(w/2), y), (x+int(w/2)-20, y-20), (x+int(w/2)+20, y-20)] )\n",
    "\t\t\t\tcv2.drawContours(img, [triangle_cnt], 0, info_box_color, -1)\n",
    "\t\t\t\tcv2.rectangle(img,(x+int(w/2)-50,y-20),(x+int(w/2)+50,y-90),info_box_color,cv2.FILLED)\n",
    "\t\t\t\t\n",
    "\t\t\t\t#labels for age and gender\n",
    "\t\t\t\tcv2.putText(img, apparent_age, (x+int(w/2), y - 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n",
    "\t\t\t\t\n",
    "\t\t\t\tif enableGenderIcons:\n",
    "\t\t\t\t\tif gender == 'M': gender_icon = male_icon\n",
    "\t\t\t\t\telse: gender_icon = female_icon\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\timg[y-75:y-75+male_icon.shape[0], x+int(w/2)-45:x+int(w/2)-45+male_icon.shape[1]] = gender_icon\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcv2.putText(img, gender, (x+int(w/2)-42, y - 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n",
    "\t\t\t\t\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(\"exception\",str(e))\n",
    "\t\t\t\n",
    "\tcv2.imshow('img',img)\n",
    "\t\n",
    "\tif cv2.waitKey(1) & 0xFF == ord('q'): #press q to quit\n",
    "\t\tbreak\n",
    "\t\n",
    "#kill open cv things\t\t\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
